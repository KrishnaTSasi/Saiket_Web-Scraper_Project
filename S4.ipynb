{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMc6crtG8sumM3+7vGXops7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KrishnaTSasi/Saiket_Web-Scraper_Project/blob/main/S4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BASIC WEB SCRAPER TASK"
      ],
      "metadata": {
        "id": "qYwMeBlPJypW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " A basic web scraper using requests and BeautifulSoup that extracts news headlines from a sample website (like BBC News)"
      ],
      "metadata": {
        "id": "Loeyl_-7MUbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL to scrape\n",
        "url = 'https://inshorts.com/en/read'\n",
        "response = requests.get(url)\n",
        "\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Headlines are inside <span itemprop=\"headline\">\n",
        "headlines = soup.find_all('span', attrs={\"itemprop\": \"headline\"})\n",
        "\n",
        "print(\"Top News Headlines:\\n\")\n",
        "for i, headline in enumerate(headlines[:10], start=1):\n",
        "    print(f\"{i}. {headline.get_text(strip=True)}\")"
      ],
      "metadata": {
        "id": "ogW6BApDKWEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaac0817-6f5e-47bf-f0c5-d7951cd2842c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top News Headlines:\n",
            "\n",
            "1. Trump plans 100% tariffs on computer chips\n",
            "2. RCB's Yash Dayal denied interim protection from arrest in rape case\n",
            "3. India, Russia sign protocol to boost industrial cooperation\n",
            "4. Sachin Tendulkar reacts to Ben Stokes handshake controversy\n",
            "5. India releases statement as Trump raises tariff to 50%, says 'Extremely unfortunate'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Headlines to File (TXT, CSV and JSON)"
      ],
      "metadata": {
        "id": "BQXURhzMMI5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "# Step 1: Extract text\n",
        "extracted_headlines = [headline.get_text(strip=True) for headline in headlines[:10]]\n",
        "\n",
        "# Step 2: Timestamp\n",
        "timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "# Save as .txt\n",
        "with open('headlines.txt', 'w', encoding='utf-8') as txt_file:\n",
        "    txt_file.write(f\"Top News Headlines ({timestamp}):\\n\\n\")\n",
        "    for i, line in enumerate(extracted_headlines, start=1):\n",
        "        txt_file.write(f\"{i}. {line}\\n\")\n",
        "\n",
        "#  Save as .csv\n",
        "with open('headlines.csv', 'w', newline='', encoding='utf-8') as csv_file:\n",
        "    writer = csv.writer(csv_file)\n",
        "    writer.writerow(['No.', 'Headline', 'Timestamp'])\n",
        "    for i, line in enumerate(extracted_headlines, start=1):\n",
        "        writer.writerow([i, line, timestamp])\n",
        "\n",
        "# Save as .json\n",
        "with open('headlines.json', 'w', encoding='utf-8') as json_file:\n",
        "    json.dump({\"timestamp\": timestamp, \"headlines\": extracted_headlines}, json_file, indent=2, ensure_ascii=False)\n",
        "print(\" Headlines saved as TXT, CSV and JSON.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce764b87-d948-4cd5-8ffb-226af07ebb1f",
        "id": "zXlFaxx8Rdou"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Headlines saved as TXT, CSV and JSON.\n"
          ]
        }
      ]
    }
  ]
}